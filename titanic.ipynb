{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic â€“ Machine Learning from the disaster\n",
    "\n",
    "First, we import these libraries below to initialize our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy._lib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/titanic.ipynb Cell 2'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/titanic.ipynb#ch0000001?line=4'>5</a>\u001b[0m \u001b[39m# Data visualizzation\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/titanic.ipynb#ch0000001?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/titanic.ipynb#ch0000001?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmissingno\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/titanic.ipynb#ch0000001?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/__init__.py?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmissingno\u001b[39;00m \u001b[39mimport\u001b[39;00m matrix\n\u001b[1;32m      <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/__init__.py?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmissingno\u001b[39;00m \u001b[39mimport\u001b[39;00m bar\n\u001b[1;32m      <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/__init__.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmissingno\u001b[39;00m \u001b[39mimport\u001b[39;00m heatmap\n",
      "File \u001b[0;32m~/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/missingno.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/missingno.py?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m gridspec\n\u001b[1;32m      <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/missingno.py?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/missingno.py?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcluster\u001b[39;00m \u001b[39mimport\u001b[39;00m hierarchy\n\u001b[1;32m      <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/missingno.py?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/missingno/missingno.py?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/scipy/__init__.py:74\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/scipy/__init__.py?line=70'>71</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__ \u001b[39mas\u001b[39;00m __numpy_version__\n\u001b[1;32m     <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/scipy/__init__.py?line=72'>73</a>\u001b[0m \u001b[39m# Import numpy symbols to scipy name space (DEPRECATED)\u001b[39;00m\n\u001b[0;32m---> <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/scipy/__init__.py?line=73'>74</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeprecation\u001b[39;00m \u001b[39mimport\u001b[39;00m _deprecated\n\u001b[1;32m     <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/scipy/__init__.py?line=74'>75</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_num\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/sinahaghighi/Documents/GitHub/310_Final/cmpt-310-final-project/cmpt310/lib/python3.9/site-packages/scipy/__init__.py?line=75'>76</a>\u001b[0m linalg \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy._lib'"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualizzation\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the data\n",
    "\n",
    "Load the data from the CSV file and understand the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "print(f\"Training set: {train.shape}\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")\n",
    "print(f\"Test set: {test.shape}\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data description\n",
    "\n",
    "- **survival**: 0 = No, 1 = Yes\n",
    "- **pclass**: Ticket class, 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- **sex**: male or female\n",
    "- **age**: age in years, is fractional if less than 1\n",
    "- **sibsp**: the number of siblings or spouses onboard\n",
    "- **parch**: the number of parents or children onboard\n",
    "- **ticket**: ticket numbers\n",
    "- **fare**: passenger fare\n",
    "- **cabin**: cabin number\n",
    "- **embarked**: port of embarkation, where C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "\n",
    "Which columns in the dataset have missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with missing data in training set\n",
    "missingno.matrix(train, figsize=(15,10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with missing data in test set\n",
    "missingno.matrix(test, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data analysis\n",
    "\n",
    "We will epxlore each variable in the data set. This may help us to choose the suitable machine learning models, or whether we need to determine the dataset.\n",
    "\n",
    "### Categorical variables\n",
    "\n",
    "- Nominal variables: **Sex**, **Emarked**\n",
    "- Oridinal variables: **Pclass**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the frequeny of each nominal variables\n",
    "cat_features = [\"Sex\", \"Embarked\", \"Pclass\"]\n",
    "f, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, feature in enumerate(cat_features):\n",
    "    sns.countplot(x=feature, data=train, ax=axes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights from counting plots\n",
    "\n",
    "- There are more male passengers than female passengers\n",
    "- Most passengers were departed from Southampton\n",
    "- Most passengers were holding third-class tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the survival rate based on each categorical variables\n",
    "f, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for i, feature in enumerate(cat_features):\n",
    "    sns.barplot(x=feature, y=\"Survived\", data=train, ax=axes[i])\n",
    "    axes[i].set_ylabel(\"Survival rate\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insights about survival plots\n",
    "\n",
    "- Female passengers were more likely to survive than male passengers. This may suggests that female passengers were prioritised to evacuate.\n",
    "- Passengers from Cherbougs were the most likely to survive, while those from Southampton were the least.\n",
    "- The higher the ticket classes were, the more likely the passengers to survived. This may suggest evacuation priority were based on the ticket class (first-class passengers first, thrid-class passengers last)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outliers\n",
    "\n",
    "Outliers are extreme values which do not conform the majority, and contribute the the skewness of the data set. Having outlier in the dataset may results in learning models with low accuracy. Therefore, we need to filter out these outliers for better models.\n",
    "\n",
    "For this dataset, the filter is based on interquatile range ($IQR$), which means we will keep the numerical values when they are in range of\n",
    "\n",
    "$$[Q_1 - 1.5 \\cdot (Q_3 - Q_1), Q_3 + 1.5 \\cdot (Q_3 - Q_1)]$$\n",
    "\n",
    "where $Q_1$ is 25th percentile, $Q_3$ is 75th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before: {len(train)} rows\")\n",
    "\n",
    "def outliersIndices():\n",
    "  numerical = train[[\"SibSp\", \"Parch\", \"Age\", \"Fare\"]]\n",
    "  q1 = numerical.quantile(.25)\n",
    "  q3 = numerical.quantile(.75)\n",
    "  iqr = q3 - q1\n",
    "  low = q1 - 1.5 * iqr\n",
    "  high = q3 + 1.5 * iqr\n",
    "  # Only filter out the data if it has more than 2 outlier fields\n",
    "  outlierCount = (~numerical.isnull() & ((numerical < low) | (numerical > high))).sum(axis=1)\n",
    "  return outlierCount[outlierCount > 2].index\n",
    "  \n",
    "indices = outliersIndices()\n",
    "print(f\"Remove rows: {list(indices)}\")\n",
    "\n",
    "# Filter out\n",
    "train = train.drop(indices, axis=0).reset_index(drop=True)\n",
    "print(f\"After: {len(train)} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation\n",
    "\n",
    "Some numerical variables may correlate with the survival state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"SibSp\", \"Parch\", \"Age\", \"Fare\"]].corrwith(train[\"Survived\"])\n",
    "\n",
    "# Comment: There is some positive correlation between the fare and survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discrete variables\n",
    "\n",
    "`SibSp` and `Parch` are discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting plots for discrete variables\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "discrete = [\"SibSp\", \"Parch\"]\n",
    "for i, feature in enumerate(discrete):\n",
    "    sns.countplot(x=feature, data=train, ax=axes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the survival rates for pasenger based on their companions\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for i, feature in enumerate(discrete):\n",
    "    sns.barplot(x=feature, y=\"Survived\", data=train, ax=axes[i])\n",
    "    axes[i].set_ylabel(\"Survival rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continuous variables\n",
    "\n",
    "`Age` and `Fare` are continuous variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the distribution for the countinuous variables?\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "continuous = [\"Age\", \"Fare\"]\n",
    "for i, feature in enumerate(continuous):\n",
    "    sns.histplot(train[feature], ax=axes[i], kde=True)\n",
    "    axes[i].annotate(\"Skewness {:.2f}\".format(train[feature].skew()), (0.5,0.5), xycoords=\"axes fraction\")\n",
    "    axes[i].set_title(f\"{feature} distribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insights from age and fare distribution\n",
    "\n",
    "- Age distribution is slightly left-skewed, where younger passengers are conrtbituted significantly to the dataset\n",
    "- Fare distribution is heavily skewed to the left, which conforms the distribution of ticket classes mentioned in the [catergorical variables analysis](#categorical-variables). Data transformation such as logarithmic transformation is needed in order to reblance the datadistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the age and fare distributions of survivors and non-sourvivors?\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.histplot(train[\"Age\"][train[\"Survived\"] == 1], kde=True, stat=\"density\", ax=axes[0])\n",
    "axes[0].set_title(\"Age distribution of survivors\")\n",
    "sns.histplot(train[\"Age\"][train[\"Survived\"] == 0], kde=True, stat=\"density\", ax=axes[1])\n",
    "axes[1].set_title(\"Age distribution of non-survivors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insights from survival age distribution\n",
    "\n",
    "- Children or passengers of young age are more likely to survive. This may suggest that chidlren were more priorised for evacuation, along with women as mentioned before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data proprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering: `Cabin`, `Ticket`, and `Name`\n",
    "\n",
    "Since `Cabin`, `Ticket`, and `Name` have too many unqiue values, we have to apply data transformation to extract some useful patterns to cut down the number of categorical values.\n",
    "\n",
    "#### New feature from `Cabin`: `Deck`\n",
    "\n",
    "The `Cabin` value is consisted of a letter follow by a number. We'll only extract the letter since it indicates the deck of the Titanic ships, which may have affect on the survival rate of the passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a letter from the cabin data\n",
    "# n = null, passenger without a cabin\n",
    "def extractDeck(data):\n",
    "  data[\"Deck\"] = data[\"Cabin\"].apply(lambda x: 'n' if pd.isnull(x) else str(x)[0])\n",
    "  data.drop(\"Cabin\", axis=1, inplace=True)\n",
    "\n",
    "extractDeck(train)\n",
    "extractDeck(test)\n",
    "\n",
    "# Count the frequency\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.countplot(x=\"Deck\", data=train, ax=axes[0])\n",
    "\n",
    "# What is the survival rate based on section?\n",
    "sns.barplot(x=\"Deck\", y=\"Survived\", data=train, ax=axes[1])\n",
    "axes[1].set_ylabel(\"Survival rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Ticket`\n",
    "\n",
    "Since the ticket values generally have letters and numbers. However, since they have many different formats, we cannot find useful pattern in the dataset. Therfore, `Ticket` was dropped from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(\"Ticket\", axis=1, inplace=True)\n",
    "test.drop(\"Ticket\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New feature from `Name`: `NameTitle`\n",
    "\n",
    "By exploring the names of the passenger, we found that most of them contains a title (such as Mr. or Mrs.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name title\n",
    "def extractTitle(data):\n",
    "  data[\"NameTitle\"] = train[\"Name\"].apply(lambda name: name.split(',')[1].split('.')[0].strip())\n",
    "  data.drop(\"Name\", axis=1, inplace=True)\n",
    "\n",
    "extractTitle(test)\n",
    "extractTitle(train)\n",
    "\n",
    "\n",
    "# What is the title distribution of name title in training set?\n",
    "pd.concat([train[\"NameTitle\"], test[\"NameTitle\"]]).value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and group titles together\n",
    "# Mme -> Mrs\n",
    "# Ms, Mlle -> Miss\n",
    "titleMap = {\n",
    "  \"Mme\": \"Mrs\", \"Mrs\": \"Mrs\", \"Mr\": \"Mr\", \"Master\": \"Master\",\n",
    "  \"Miss\": \"Miss\", \"Ms\": \"Miss\", \"Mlle\": \"Miss\",\n",
    "}\n",
    "def cleanTitle(title: str):\n",
    "  if title in titleMap:\n",
    "    return titleMap[title]\n",
    "  return \"Other\"\n",
    "\n",
    "# Now, we only have 5 cateogries for name title: Mr, Mrs, Miss, Master, Other\n",
    "train[\"NameTitle\"] = train[\"NameTitle\"].apply(cleanTitle)\n",
    "test[\"NameTitle\"] = test[\"NameTitle\"].apply(cleanTitle)\n",
    "\n",
    "# What is the distrubution and the survival rate?\n",
    "f, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.countplot(x=\"NameTitle\", data=train, ax=axes[0])\n",
    "axes[0].set_xlabel(\"Name Title\")\n",
    "\n",
    "sns.barplot(x=\"NameTitle\", y=\"Survived\", data=train, ax=axes[1])\n",
    "axes[1].set_xlabel(\"Name Title\")\n",
    "axes[1].set_ylabel(\"Survival rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data from training set\n",
    "missing = train.isnull().sum()\n",
    "missing[missing > 0].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data from test set\n",
    "missing = test.isnull().sum()\n",
    "missing[missing > 0].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `Embarked` in the training set, the missing data is filled with the most common one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Embarked\"].fillna(train[\"Embarked\"].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `Fare` in the test set, the missing data is filled with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Fare\"].fillna(test[\"Fare\"].dropna().median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling `Age` info\n",
    "\n",
    "As mentioned before, there are signifincant portion of  passengers without age info.\n",
    "\n",
    "From the result below, `Pclass`, `Parch`, and `SibSp` are somewhat correlation with `Age`. We can use this information to fill the missing `Age` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary encoding for sex\n",
    "train[\"Sex\"] = train[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "test[\"Sex\"] = test[\"Sex\"].map({\"male\": 0, \"female\": 1})\n",
    "\n",
    "# What is the correlation for between categorical and discrete variable and the age?\n",
    "train[[\"Sex\", \"Pclass\", \"SibSp\", \"Parch\"]].corrwith(train[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How about in the test set?\n",
    "test[[\"Sex\", \"Pclass\", \"SibSp\", \"Parch\"]].corrwith(test[\"Age\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From both correlation tables above, we found that the `Age` is most correlated to the `Pclass`. We'll that information to fill the missing `Age` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows with with missing Age\n",
    "def fillAge(data):\n",
    "  missingAgeRows = data[data[\"Age\"].isnull()].index.tolist()\n",
    "  meadianAge = data[\"Age\"].dropna().median()\n",
    "\n",
    "  for i in missingAgeRows:\n",
    "    # Find the rows with the same Pclass\n",
    "    predictedAge = data[data[\"Pclass\"] == data.loc[i ,\"Pclass\"]][\"Age\"].median()\n",
    "    if pd.isnull(predictedAge):\n",
    "      data.loc[i, \"Age\"] = meadianAge\n",
    "    else:\n",
    "      data.loc[i, \"Age\"] = predictedAge\n",
    "\n",
    "fillAge(train)\n",
    "fillAge(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data encoding\n",
    "\n",
    "From the current state of the dataset, `Sex` are `Pclass` are previously encoded with numerical values.\n",
    "\n",
    "Since `NameTitle`, `Deck`, and `Embarked` are nomimal values where each of them has a small number categories, we'll use **Dummy Encoding** scheme for these variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the remaining categorical data\n",
    "categorical = [\"NameTitle\", \"Deck\", \"Embarked\"]\n",
    "categoricalWithId = [\"PassengerId\"] + categorical\n",
    "combinedCat = pd.concat([train[categoricalWithId], test[categoricalWithId]], ignore_index=True)\n",
    "combinedCat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy encoding\n",
    "dummies = pd.get_dummies(combinedCat[categorical])\n",
    "dummies = pd.concat([combinedCat[\"PassengerId\"], dummies], axis=1)\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dummy table to the data set\n",
    "train = train.drop(categorical, axis=1).merge(dummies, \"left\", \"PassengerId\")\n",
    "test = test.drop(categorical, axis=1).merge(dummies, \"left\", \"PassengerId\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine age and fare data from the training and test set\n",
    "numerical = [\"Age\", \"Fare\"]\n",
    "numericalWithId = [\"PassengerId\"] + numerical\n",
    "combinedNum = pd.concat([train[numericalWithId], test[numericalWithId]], ignore_index=True)\n",
    "combinedNum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Age` encoding\n",
    "\n",
    "As mentioned before, the age distribution is quite normal. Thus, we can directly encode it by transform it into ordinal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedNum[\"AgeClass\"] = pd.cut(combinedNum[\"Age\"], 5, labels=range(5))\n",
    "combinedNum.drop([\"Age\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Fare` encoding\n",
    "\n",
    "As mentioned before, the distribution of `Fare` is heavily skewed to the left. This suggests we should perform data transformation on this data before encoding it. In this case, we choose logarithmic transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic transformation\n",
    "combinedNum[\"LogFare\"] = np.log(combinedNum[\"Fare\"] + 1)\n",
    "\n",
    "# What is the distribution?\n",
    "print(f\"Skewness: {combinedNum['LogFare'].skew():.2f}\")\n",
    "sns.histplot(combinedNum[\"LogFare\"], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode to ordinal values\n",
    "combinedNum[\"FareClass\"] = pd.cut(combinedNum[\"LogFare\"], 6, labels=range(6))\n",
    "\n",
    "# Drop the temporary columns\n",
    "combinedNum.drop([\"Fare\", \"LogFare\"], axis=1, inplace=True)\n",
    "\n",
    "# What is the result look like\n",
    "combinedNum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the new encoded data back to the original set\n",
    "train = train.drop(numerical, axis=1).merge(combinedNum, \"left\", \"PassengerId\")\n",
    "test = test.drop(numerical, axis=1).merge(combinedNum, \"left\", \"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final data before modelling\n",
    "\n",
    "Let's see the structure of two data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does training set look like?\n",
    "print(f\"Training set: {train.shape}\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does test set look like?\n",
    "print(f\"Test set: {test.shape}\")\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning\n",
    "\n",
    "First, import libraries for machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "First, we eill build the data set to input the learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([\"PassengerId\", \"Survived\"], axis=1)\n",
    "y = train[\"Survived\"]\n",
    "X_test = train.drop(\"PassengerId\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning models\n",
    "\n",
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "randomForest = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)\n",
    "randomForest.fit(X, y)\n",
    "score = randomForest.score(X, y)\n",
    "print(f\"Accuracy {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X, y)\n",
    "score = neigh.score(X, y)\n",
    "print(f\"Accuracy {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression()\n",
    "reg.fit(X, y)\n",
    "score = reg.score(X, y)\n",
    "print(f\"Accuracy {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X, y)\n",
    "score = clf.score(X, y)\n",
    "print(f\"Accuracy {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "splitIndices = kf.split(train)\n",
    "\n",
    "def kFoldLearning(model):\n",
    "    scores = []\n",
    "    for train_index, test_index in splitIndices:\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "        X_test, y_test = X[test_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        scores.append(model.score(X_test, y_test))\n",
    "    print(f\"Average accuracy: {sum(scores) / len(scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c5914b07774828d88e484de19b56e070a27985c19099e1265214c8aab0dc9dc9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
